{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"7.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNe8qg+J76Kkig/iauNPgQb"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"MN_jKxcC1XJX"},"source":["#7"]},{"cell_type":"code","metadata":{"id":"1cBe4kerHSCB","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1638364538334,"user_tz":-330,"elapsed":67854,"user":{"displayName":"HARSHITH GANDHE","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhqqtCT1oqiyI5Eh9zv6fQFnG0ICZb1-YGmzniD-g=s64","userId":"10725924555064938006"}},"outputId":"da380561-c13e-4708-acd3-46a7986bc7b5"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","metadata":{"id":"wdMgLOxqIbyV","executionInfo":{"status":"ok","timestamp":1638364621464,"user_tz":-330,"elapsed":521,"user":{"displayName":"HARSHITH GANDHE","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhqqtCT1oqiyI5Eh9zv6fQFnG0ICZb1-YGmzniD-g=s64","userId":"10725924555064938006"}}},"source":["%reset-f\n","import numpy as np\n","import pandas as pd\n","from sklearn.metrics import confusion_matrix as cm\n","from numpy import random\n","data = pd.read_excel('/content/drive/MyDrive/ML/data5.xlsx', header = None)"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8NfsprLMIwc1","executionInfo":{"status":"ok","timestamp":1638364670379,"user_tz":-330,"elapsed":11594,"user":{"displayName":"HARSHITH GANDHE","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhqqtCT1oqiyI5Eh9zv6fQFnG0ICZb1-YGmzniD-g=s64","userId":"10725924555064938006"}},"outputId":"b9423e41-7fd2-4fde-fb3f-e733993865c8"},"source":["data = np.array(data)\n","np.random.shuffle(data)\n","\n","def initialize(data):\n","  X = np.array(data[:,:-1], dtype = float)\n","  y = np.array(data[:,-1], dtype = int)\n","  X = (X - X.mean(axis = 0))/X.std(axis = 0)\n","  return X, y\n","\n","X_total, y_total = initialize(data)\n","y = np.zeros((len(y_total), 3))\n","for i in range(len(y_total)):\n","  if y_total[i] == 1:\n","    y[i,0] = 1.0\n","  elif y_total[i] == 2:\n","    y[i,1] = 1.0\n","  elif y_total[i] == 3:\n","    y[i,2] = 1.0\n","\n","X_train, y_train = X_total[:int(0.7 * len(X_total))], y[:int(0.7 * len(X_total))]\n","X_validation, y_validation = X_total[int(0.7 * len(X_total)):], y[int(0.7 * len(X_total)):]\n","alpha = 0.5\n","\n","# Sigmoid Function\n","def sigmoid(x, derivative = False):\n","  if derivative == True:\n","    return x * (1 - x)\n","  return 1/(1 + np.exp(-x))\n","\n","# tanh(x) activation function\n","def tanh(x):\n","  return np.tanh(x)\n","\n","# Cost Function calculation\n","def cost_calculation(neuralNetwork, x, y):\n","  cost = 0\n","  for i in range(len(x)):\n","    X = np.reshape(x[i], (len(x[i]), 1))\n","    cost += 0.5/len(x) * np.sum((y[i] - neuralNetwork.forward_propagation(X)) ** 2)\n","  return cost\n","\n","# Class for the neural network\n","class NeuralNetwork(object):\n","  def __init__(self, sizes):\n","    self.number_layers = len(sizes)\n","    self.sizes = sizes\n","    self.weight = {}\n","    self.activation = {} # The activation values\n","    self.bias = {} # The bias values\n","\n","    # Initialize the weights\n","    for i in range(1, self.number_layers):\n","      self.weight[i] = np.random.randn(self.sizes[i-1], self.sizes[i])\n","    \n","    # Initialize the biases\n","    for i in range(1, self.number_layers):\n","      self.bias[i] = np.random.randn(self.sizes[i], 1)\n","\n","    # Initialize the activations\n","    for i in range(1, self.number_layers):\n","      self.activation[i] = np.zeros([self.sizes[i], 1])\n","  \n","  def forward_propagation(self, X):\n","    self.activation[0] = X\n","    for i in range(1, self.number_layers):\n","      self.activation[i] = sigmoid(np.dot(self.weight[i].T, self.activation[i-1]) + self.bias[i])\n","    return self.activation[self.number_layers - 1]\n","  \n","  def backward_propagation(self, X, y, output):\n","    self.d = {}\n","    self.d_output = (y - output) * sigmoid(output, derivative = True)\n","    self.d[self.number_layers - 1] = self.d_output\n","\n","    # Derivatives of the layers\n","    for i in range(self.number_layers - 1, 1, -1):\n","      self.d[i-1] = np.dot(self.weight[i], self.d[i]) * sigmoid(self.activation[i-1], derivative = True)\n","\n","    # Updating weights\n","    for i in range(1, self.number_layers - 1):\n","      self.weight[i] += alpha * np.dot(self.activation[i-1], self.d[i].T)\n","    \n","    # Updating biases\n","    for i in range(1, self.number_layers - 1):\n","      self.bias[i] += alpha * self.d[i]\n","  \n","  def training_process(self, X, y):\n","    X = np.reshape(X, (len(X), 1))\n","    output = self.forward_propagation(X)\n","    self.backward_propagation(X, y, output)\n","\n","  def get_weight(self):\n","    return self.weight\n","  \n","  def load_weights(self, weight):\n","    self.weight = weight\n","\n","  def get_activation(self, X):\n","    X = np.reshape(X, (len(X), 1))\n","    self.forward_propagation(X)\n","    return self.activation\n","  \n","  def load_activations(self, activation):\n","    self.activation = activation\n","\n","# Initialization of the autoencoders and the ELM\n","autoencoder1 = NeuralNetwork([7,6,7])\n","autoencoder2 = NeuralNetwork([6,3,6])\n","\n","\n","for i in range(500):\n","  for j, row in enumerate(X_train):\n","    row = np.reshape(row, (7,1))\n","    autoencoder1.training_process(row, row)\n","  \n","  cost = cost_calculation(autoencoder1, X_train, X_train)\n","\n","   \n","\n","autoencoder2_input = []\n","for row in X_train:\n","  autoencoder2_input.append(autoencoder1.get_activation(row)[1])\n","\n","autoencoder2_input = np.array(autoencoder2_input)\n","\n","\n","# Autoencoder 2 Pre-training\n","for i in range(500):\n","  for j, row in enumerate(autoencoder2_input):\n","    row = np.reshape(row, (6, 1))\n","    autoencoder2.training_process(row, row)\n","  \n","  cost = cost_calculation(autoencoder2, autoencoder2_input, autoencoder2_input)\n","\n","\n","\n","# Input to the ELM\n","elm_input = []\n","for row in autoencoder2_input:\n","  elm_input.append(autoencoder2.get_activation(row)[1])\n","elm_input = np.array(elm_input)\n","\n","# Parameters of the ELM\n","elm_neurons = 25\n","output_neurons = 3\n","weight_elm = np.random.randn(elm_input.shape[1], elm_neurons)\n","\n","# Training of ELM\n","np.random.seed(1)\n","elm_input = np.reshape(elm_input, (147, 3))\n","H = np.matmul(elm_input, weight_elm)\n","H = tanh(H)\n","H_inv = np.linalg.pinv(H)\n","weight_final = np.matmul(H_inv, y_train)\n","\n","# Autoencoder 1 forward propagation\n","layer1_output = []\n","for i, row in enumerate(X_validation):\n","  activation = autoencoder1.get_activation(row)[1]\n","  layer1_output.append(activation)\n","layer1_output = np.array(layer1_output)\n","layer1_output = np.reshape(layer1_output, (63, 6))\n","\n","# Autoencoder 2 forward propagation\n","layer2_output = []\n","for i, row in enumerate(layer1_output):\n","  activation = autoencoder2.get_activation(row)[1]\n","  layer2_output.append(activation)\n","layer2_output = np.array(layer2_output)\n","layer2_output = np.reshape(layer2_output, (63, 3))\n","\n","# ELM forward propagation\n","ht = np.matmul(layer2_output, weight_elm)\n","ht = tanh(ht)\n","y_prediction = np.matmul(ht, weight_final)\n","\n","activation = [np.argmax(y_prediction[i]) for i in range(len(y_prediction))]\n","bias = [np.argmax(y_validation[i]) for i in range(len(y_validation))]\n","\n","confusion_matrix = cm(bias, activation)\n","\n","confusion_matrix = np.array(confusion_matrix)\n","\n","accuracy1 = (confusion_matrix[0][0])/(confusion_matrix[0][0] + confusion_matrix[0][1] + confusion_matrix[0][2])\n","accuracy2 = (confusion_matrix[1][1])/(confusion_matrix[1][0] + confusion_matrix[1][1] + confusion_matrix[1][2])\n","accuracy3 = (confusion_matrix[2][2])/(confusion_matrix[2][0] + confusion_matrix[2][1] + confusion_matrix[2][2])\n","\n","sum_allelements = 0.0\n","for i in range(3):\n","  for j in range(3):\n","    sum_allelements += confusion_matrix[i][j]\n","\n","numerator = (confusion_matrix[0][0] + confusion_matrix[1][1] + confusion_matrix[2][2])\n","overall_accuracy = numerator/sum_allelements\n","\n","# Finding the accuracies\n","print(\"class1 accuracy \", accuracy1)\n","print(\"class2 accuracy \", accuracy2)\n","print(\"class3 accuracy\", accuracy3)\n","print(\"overall accuracy  \", overall_accuracy)"],"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["class1 accuracy  0.9444444444444444\n","class2 accuracy  0.875\n","class3 accuracy 0.7142857142857143\n","overall accuracy   0.8412698412698413\n"]}]}]}