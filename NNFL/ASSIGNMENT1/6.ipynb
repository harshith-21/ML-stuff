{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"6.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"DCQpijs0jQhi"},"source":["### ***6***"]},{"cell_type":"markdown","metadata":{"id":"mbrsC-wMpWK9"},"source":["# Multiclass Logistic Regression + BGD"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"id":"eXp7-E-KHUAU","executionInfo":{"status":"ok","timestamp":1634024184944,"user_tz":-330,"elapsed":21566,"user":{"displayName":"HARSHITH GANDHE","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhqqtCT1oqiyI5Eh9zv6fQFnG0ICZb1-YGmzniD-g=s64","userId":"10725924555064938006"}},"outputId":"8b45b2f6-5d81-48ae-9b4d-a6f1ba5eec27"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","metadata":{"id":"huCtbDj0HlOK","executionInfo":{"status":"ok","timestamp":1634024184944,"user_tz":-330,"elapsed":8,"user":{"displayName":"HARSHITH GANDHE","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhqqtCT1oqiyI5Eh9zv6fQFnG0ICZb1-YGmzniD-g=s64","userId":"10725924555064938006"}}},"source":["%reset-f"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"SVr6I7QvtTCZ","executionInfo":{"status":"ok","timestamp":1634024184944,"user_tz":-330,"elapsed":7,"user":{"displayName":"HARSHITH GANDHE","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhqqtCT1oqiyI5Eh9zv6fQFnG0ICZb1-YGmzniD-g=s64","userId":"10725924555064938006"}}},"source":["import pandas as pd\n","import numpy as np\n","from matplotlib import pyplot as plt \n","import math\n","import copy"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"MuUrBD4etW9W","executionInfo":{"status":"ok","timestamp":1634024184945,"user_tz":-330,"elapsed":7,"user":{"displayName":"HARSHITH GANDHE","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhqqtCT1oqiyI5Eh9zv6fQFnG0ICZb1-YGmzniD-g=s64","userId":"10725924555064938006"}}},"source":["path = '/content/drive/MyDrive/ML/data_q6_q7.xlsx' \n","df = pd.read_excel(path)\n","insts = df.to_numpy()\n","m= len(insts[:,0]) #No of instinces\n","ones = np.ones((m,1))\n","insts = np.append(ones,insts,axis=1)\n","n = len(insts[0,:])-1 #no of features including f0 n=31\n","for i in range(1,n,1):\n","  insts[:,i] = (insts[:,i] - insts[:,i].mean())/insts[:,i].std() #Normalize the data\n","insts_mb = copy.deepcopy(insts)\n","insts_s = copy.deepcopy(insts)\n","np.random.shuffle(insts)\n","insts_tr = insts[0:int(m*0.7),:]\n","insts_te = insts[int(m*0.7):int(m*0.9),:]\n","insts_val = insts[int(m*0.9):m,:]"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"J4xNY4okuR4t","executionInfo":{"status":"ok","timestamp":1634024185573,"user_tz":-330,"elapsed":634,"user":{"displayName":"HARSHITH GANDHE","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhqqtCT1oqiyI5Eh9zv6fQFnG0ICZb1-YGmzniD-g=s64","userId":"10725924555064938006"}}},"source":["# hypothesis for logistic regression which is the prediction \n","def hypothesis(w,insts,m,n):\n","  z = np.dot(insts[:,0:n],w.T)\n","  h = 1/(1+np.exp(-z.astype(np.float32))) #working\n","  return h\n","\n","# cost function for logistic regression\n","def cost(h,insts,m):\n","  c = 0\n","  for i in range(m):\n","    c_te = (-insts_tr[i,-1]*np.log(h[i]) - (1- insts_tr[i,-1])*np.log(1 - h[i]))/m\n","    if not(np.isnan(c_te)) and not(math.isinf(c_te)):\n","      c = c+ c_te\n","  return c\n","# update of weight values for logistic regression\n","def update(w,alpha,insts,h,m,n):\n","  d = np.zeros(n)\n","  for i in range(n):\n","    d[i] = np.dot( (h[0:m]- insts[0:m,-1]),insts[0:m,i] )\n","  for i in range(n):\n","    w[i] = w[i] - alpha*d[i]\n","\n","  return w\n","def update_stotastic(w,alpha,insts,h,index,n):\n","  d = np.zeros(n)\n","  for i in range(n):\n","    d[i] = (h[index]- insts[index,-1])*insts[index,i] \n","  for i in range(n):\n","    w[i] = w[i] - alpha*d[i]\n","\n","  return w\n","\n","def performance(mat,m):\n","  for i in range(3):\n","    ia = mat[i,i]/(mat[i,0]+mat[i,1]+mat[i,2])\n","    print('accuracy for group',end='')\n","    print(i+1, end=': ')\n","    print(ia)\n","  print('overall accuracy:',end= ' ')\n","  print((mat[0,0]+mat[1,1]+mat[2,2])/m)\n","\n","  "],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"tU0l-CjZyTiM","executionInfo":{"status":"ok","timestamp":1634024185574,"user_tz":-330,"elapsed":5,"user":{"displayName":"HARSHITH GANDHE","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhqqtCT1oqiyI5Eh9zv6fQFnG0ICZb1-YGmzniD-g=s64","userId":"10725924555064938006"}}},"source":["opt_weights = [] # stores the weight values for all the models\n","opt_cost = [] # stores the final optimal cost value at the end of each group"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"2BRrJ7N8xIgj","executionInfo":{"status":"ok","timestamp":1634024197123,"user_tz":-330,"elapsed":11554,"user":{"displayName":"HARSHITH GANDHE","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhqqtCT1oqiyI5Eh9zv6fQFnG0ICZb1-YGmzniD-g=s64","userId":"10725924555064938006"}}},"source":["for i in range(1,4):\n","  train = insts_tr.copy()\n","  val = insts_val.copy()\n","  train[:,-1] = (train[:,-1]==i).astype(int) # assignes the value 1 if the level is i\n","  val[:,-1] = (val[:,-1]==i).astype(int)# assignes the value 0 if the level is not i\n","  m_tr = len(train[:,0])\n","  m_val = len(val[:,0])\n","  itr = 600\n","  alpha = np.linspace(0.001,0.01,100)\n","  b_min = 10000\n","  c = np.ones(len(alpha))\n","  w_opt = np.zeros(n)  #stores the optimal weight value\n","  min=0\n","  for j in range(len(alpha)):\n","    w = np.random.rand(n)\n","    j_list = np.ones(itr)\n","    for k in range(itr):\n","      h = hypothesis(w,train,m_tr,n)\n","      w = update(w,alpha[j],train,h,m_tr,n)\n","    h = hypothesis(w,val,m_val,n)\n","    c[j] = cost(h,val,m_val)\n","    if c[j] < b_min:\n","      min = j\n","      b_min = c[j]\n","      w_opt = w  \n","  h = hypothesis(w_opt,train,m_tr,n)\n","  opt_cost.append(cost(h,train,m_tr)) # cal the final cost value\n","  opt_weights.append(w_opt) # append the optimal weight values for every group"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"lqiVD6Cg3QIQ","executionInfo":{"status":"ok","timestamp":1634024197124,"user_tz":-330,"elapsed":20,"user":{"displayName":"HARSHITH GANDHE","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhqqtCT1oqiyI5Eh9zv6fQFnG0ICZb1-YGmzniD-g=s64","userId":"10725924555064938006"}}},"source":["m_te = len(insts_te[:,0])\n","y_acu = insts_te[:,-1].astype(int)\n","y_pre = np.zeros(len(insts_te)).astype(int)\n","y_cost = np.zeros(len(insts_te))\n","i = 1\n","for w in opt_weights:\n","  h_te = hypothesis(w,insts_te,m_te,n)\n","  y_pe = np.round(h_te)\n","  for j in range(len(y_pe)):\n","    if y_pe[j]==1 and y_cost[j]==0:\n","      y_pre[j] = i\n","      y_cost[j] = opt_cost[i-1]\n","    if y_pe[j] == 1 and y_cost[j] !=0:\n","      if y_cost[j]>opt_cost[i-1]:\n","        y_pre[j] = i\n","        y_cost[j] = opt_cost[i-1]\n","  i+=1\n","\n","  "],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"id":"l0JP-BktxIQJ","executionInfo":{"status":"ok","timestamp":1634024197124,"user_tz":-330,"elapsed":19,"user":{"displayName":"HARSHITH GANDHE","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhqqtCT1oqiyI5Eh9zv6fQFnG0ICZb1-YGmzniD-g=s64","userId":"10725924555064938006"}},"outputId":"17ba6f41-def3-4a83-c932-bd75ea060c37"},"source":["confusion_matrix = np.zeros(9).reshape(3,3)\n","\n","for i in range(m_te):\n","  if y_pre[i] == y_acu[i]:\n","    idx = y_acu[i]\n","    confusion_matrix[idx-1,idx-1] +=1\n","  else:\n","    confusion_matrix[y_acu[i]-1,y_pre[i]-1] +=1\n","confusion_matrix"],"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[11.,  0.,  1.],\n","       [ 1., 13.,  0.],\n","       [ 0.,  0., 16.]])"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"id":"PHPtnm2sEmjC","executionInfo":{"status":"ok","timestamp":1634024197125,"user_tz":-330,"elapsed":16,"user":{"displayName":"HARSHITH GANDHE","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhqqtCT1oqiyI5Eh9zv6fQFnG0ICZb1-YGmzniD-g=s64","userId":"10725924555064938006"}},"outputId":"eed11953-29dc-4e7c-bced-3cdc1662fa5a"},"source":["performance(confusion_matrix,m_te)"],"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["accuracy for group1: 0.9166666666666666\n","accuracy for group2: 0.9285714285714286\n","accuracy for group3: 1.0\n","overall accuracy: 0.9523809523809523\n"]}]},{"cell_type":"markdown","metadata":{"id":"m43wfY4SA5qY"},"source":["# Multiclass Logistic regression + MBG"]},{"cell_type":"code","metadata":{"id":"Sy3ZfijWHUK6","executionInfo":{"status":"ok","timestamp":1634024197125,"user_tz":-330,"elapsed":12,"user":{"displayName":"HARSHITH GANDHE","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhqqtCT1oqiyI5Eh9zv6fQFnG0ICZb1-YGmzniD-g=s64","userId":"10725924555064938006"}}},"source":["np.random.shuffle(insts_mb)\n","insts_tr = insts_mb[0:int(m*0.7),:]\n","insts_te = insts_mb[int(m*0.7):int(m*0.9),:]\n","insts_val = insts_mb[int(m*0.9):m,:]"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"FAIhxhjODAUq","executionInfo":{"status":"ok","timestamp":1634024197126,"user_tz":-330,"elapsed":13,"user":{"displayName":"HARSHITH GANDHE","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhqqtCT1oqiyI5Eh9zv6fQFnG0ICZb1-YGmzniD-g=s64","userId":"10725924555064938006"}}},"source":["opt_weights_mb = [] # stores the weight values for all the models\n","opt_cost_mb = [] # stores the final optimal cost value at the end of each group"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"id":"KJxIA9PwFEDO","executionInfo":{"status":"ok","timestamp":1634024246459,"user_tz":-330,"elapsed":49346,"user":{"displayName":"HARSHITH GANDHE","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhqqtCT1oqiyI5Eh9zv6fQFnG0ICZb1-YGmzniD-g=s64","userId":"10725924555064938006"}},"outputId":"e1579fee-09ee-486b-8bce-20963a8efad3"},"source":["for i in range(1,4):\n","  train = insts_tr.copy()\n","  val = insts_val.copy()\n","  train[:,-1] = (train[:,-1]==i).astype(int) # assignes the value 1 if the level is i\n","  val[:,-1] = (val[:,-1]==i).astype(int)# assignes the value 0 if the level is not i\n","  m_tr = len(train[:,0])\n","  m_val = len(val[:,0])\n","  itr = 600\n","  alpha = np.linspace(0.001,0.01,100)\n","  b_min = 10000\n","  c = np.ones(len(alpha))\n","  w_opt = np.zeros(n)  #stores the optimal weight value\n","  min=0\n","  m_batch = 20\n","  for j in range(len(alpha)):\n","    w = np.random.rand(n)\n","    j_list = np.ones(itr)\n","    for k in range(itr):\n","      np.random.shuffle(train)\n","      h = hypothesis(w,train,m_tr,n)\n","      w = update(w,alpha[j],train,h,m_batch,n)\n","    h = hypothesis(w,val,m_val,n)\n","    c[j] = cost(h,val,m_val)\n","    if c[j] < b_min:\n","      min = j\n","      b_min = c[j]\n","      w_opt = w  \n","  h = hypothesis(w_opt,train,m_tr,n)\n","  opt_cost_mb.append(cost(h,train,m_tr)) # cal the final cost value\n","  opt_weights_mb.append(w_opt) # append the optimal weight values for every group\n","m_te = len(insts_te[:,0])\n","y_acu = insts_te[:,-1].astype(int)\n","y_pre = np.zeros(len(insts_te)).astype(int)\n","y_cost = np.zeros(len(insts_te))\n","i = 1\n","for w in opt_weights_mb:\n","  h_te = hypothesis(w,insts_te,m_te,n)\n","  y_pe = np.round(h_te)\n","  for j in range(len(y_pe)):\n","    if y_pe[j]==1 and y_cost[j]==0:\n","      y_pre[j] = i\n","      y_cost[j] = opt_cost_mb[i-1]\n","    if y_pe[j] == 1 and y_cost[j] !=0:\n","      if y_cost[j]>opt_cost_mb[i-1]:\n","        y_pre[j] = i\n","        y_cost[j] = opt_cost_mb[i-1]\n","  i+=1\n","confusion_matrix = np.zeros(9).reshape(3,3)\n","\n","for i in range(m_te):\n","  if y_pre[i] == y_acu[i]:\n","    idx = y_acu[i]\n","    confusion_matrix[idx-1,idx-1] +=1\n","  else:\n","    confusion_matrix[y_acu[i]-1,y_pre[i]-1] +=1\n","performance(confusion_matrix,m_te)\n","  "],"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["accuracy for group1: 0.6875\n","accuracy for group2: 1.0\n","accuracy for group3: 0.9230769230769231\n","overall accuracy: 0.8571428571428571\n"]}]},{"cell_type":"markdown","metadata":{"id":"7_WsM69ABga7"},"source":["# Multiclass Logistic regression + SGD"]},{"cell_type":"code","metadata":{"id":"p9vouq58Bjjk","executionInfo":{"status":"ok","timestamp":1634024246459,"user_tz":-330,"elapsed":11,"user":{"displayName":"HARSHITH GANDHE","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhqqtCT1oqiyI5Eh9zv6fQFnG0ICZb1-YGmzniD-g=s64","userId":"10725924555064938006"}}},"source":["np.random.shuffle(insts_s)\n","insts_tr = insts_s[0:int(m*0.7),:]\n","insts_te = insts_s[int(m*0.7):int(m*0.9),:]\n","insts_val = insts_s[int(m*0.9):m,:]"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"-02kDxLLI0PW","executionInfo":{"status":"ok","timestamp":1634024246460,"user_tz":-330,"elapsed":11,"user":{"displayName":"HARSHITH GANDHE","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhqqtCT1oqiyI5Eh9zv6fQFnG0ICZb1-YGmzniD-g=s64","userId":"10725924555064938006"}}},"source":["opt_weights_s = [] # stores the weight values for all the models\n","opt_cost_s = [] # stores the final optimal cost value at the end of each group"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"id":"tFeqm9E0Grww","executionInfo":{"status":"ok","timestamp":1634024265106,"user_tz":-330,"elapsed":18656,"user":{"displayName":"HARSHITH GANDHE","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhqqtCT1oqiyI5Eh9zv6fQFnG0ICZb1-YGmzniD-g=s64","userId":"10725924555064938006"}},"outputId":"d7212b1a-7203-4b5c-e0bc-4ebf203cea48"},"source":["\n","for i in range(1,4):\n","  train = insts_tr.copy()\n","  val = insts_val.copy()\n","  train[:,-1] = (train[:,-1]==i).astype(int) # assignes the value 1 if the level is i\n","  val[:,-1] = (val[:,-1]==i).astype(int)# assignes the value 0 if the level is not i\n","  m_tr = len(train[:,0])\n","  m_val = len(val[:,0])\n","  itr = 1000\n","  alpha = np.linspace(0.01,0.1,100)\n","  b_min = 10000\n","  c = np.ones(len(alpha))\n","  w_opt = np.zeros(n)  #stores the optimal weight value\n","  min=0\n","  for j in range(len(alpha)):\n","    w = np.random.rand(n)\n","    j_list = np.ones(itr)\n","    for k in range(itr):\n","      index = np.random.randint(0,m_tr)\n","      h = hypothesis(w,train,m_tr,n)\n","      w = update_stotastic(w,alpha[j],train,h,index,n)\n","    h = hypothesis(w,val,m_val,n)\n","    c[j] = cost(h,val,m_val)\n","    if c[j] < b_min:\n","      min = j\n","      b_min = c[j]\n","      w_opt = w  \n","  h = hypothesis(w_opt,train,m_tr,n)\n","  opt_cost_s.append(cost(h,train,m_tr)) # cal the final cost value\n","  opt_weights_s.append(w_opt) # append the optimal weight values for every group\n","m_te = len(insts_te[:,0])\n","y_acu = insts_te[:,-1].astype(int)\n","y_pre = np.zeros(len(insts_te)).astype(int)\n","y_cost = np.zeros(len(insts_te))\n","i = 1\n","for w in opt_weights_s:\n","  h_te = hypothesis(w,insts_te,m_te,n)\n","  y_pe = np.round(h_te)\n","  for j in range(len(y_pe)):\n","    if y_pe[j]==1 and y_cost[j]==0:\n","      y_pre[j] = i\n","      y_cost[j] = opt_cost_s[i-1]\n","    if y_pe[j] == 1 and y_cost[j] !=0:\n","      if y_cost[j]>opt_cost_s[i-1]:\n","        y_pre[j] = i\n","        y_cost[j] = opt_cost_s[i-1]\n","  i+=1\n","confusion_matrix = np.zeros(9).reshape(3,3)\n","\n","for i in range(m_te):\n","  if y_pre[i] == y_acu[i]:\n","    idx = y_acu[i]\n","    confusion_matrix[idx-1,idx-1] +=1\n","  else:\n","    confusion_matrix[y_acu[i]-1,y_pre[i]-1] +=1\n","performance(confusion_matrix,m_te)\n","  "],"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["accuracy for group1: 0.5333333333333333\n","accuracy for group2: 1.0\n","accuracy for group3: 1.0\n","overall accuracy: 0.8333333333333334\n"]}]},{"cell_type":"markdown","metadata":{"id":"twx_-9JzBkE0"},"source":["# Multiclass Logistic regression + BGD + L2-NORM"]},{"cell_type":"code","metadata":{"id":"C6aGwH4LBqPW","executionInfo":{"status":"ok","timestamp":1634024265107,"user_tz":-330,"elapsed":11,"user":{"displayName":"HARSHITH GANDHE","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhqqtCT1oqiyI5Eh9zv6fQFnG0ICZb1-YGmzniD-g=s64","userId":"10725924555064938006"}}},"source":["%reset-f"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"mgoCednaKDn3","executionInfo":{"status":"ok","timestamp":1634024265107,"user_tz":-330,"elapsed":10,"user":{"displayName":"HARSHITH GANDHE","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhqqtCT1oqiyI5Eh9zv6fQFnG0ICZb1-YGmzniD-g=s64","userId":"10725924555064938006"}}},"source":["import pandas as pd\n","import numpy as np\n","from matplotlib import pyplot as plt \n","import math\n","import copy"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"rjU64o0XKD92","executionInfo":{"status":"ok","timestamp":1634024265107,"user_tz":-330,"elapsed":10,"user":{"displayName":"HARSHITH GANDHE","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhqqtCT1oqiyI5Eh9zv6fQFnG0ICZb1-YGmzniD-g=s64","userId":"10725924555064938006"}}},"source":["path = '/content/drive/MyDrive/ML/data_q6_q7.xlsx' \n","df = pd.read_excel(path)\n","insts = df.to_numpy()\n","m= len(insts[:,0]) #No of instinces\n","ones = np.ones((m,1))\n","insts = np.append(ones,insts,axis=1)\n","n = len(insts[0,:])-1 #no of features including f0 n=31\n","for i in range(1,n,1):\n","  insts[:,i] = (insts[:,i] - insts[:,i].mean())/insts[:,i].std() #Normalize the data\n","insts_mb = copy.deepcopy(insts)\n","insts_s = copy.deepcopy(insts)\n","np.random.shuffle(insts)\n","insts_tr = insts[0:int(m*0.7),:]\n","insts_te = insts[int(m*0.7):int(m*0.9),:]\n","insts_val = insts[int(m*0.9):m,:]"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"LIJlI6xqKES0","executionInfo":{"status":"ok","timestamp":1634024265108,"user_tz":-330,"elapsed":11,"user":{"displayName":"HARSHITH GANDHE","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhqqtCT1oqiyI5Eh9zv6fQFnG0ICZb1-YGmzniD-g=s64","userId":"10725924555064938006"}}},"source":["# hypothesis for logistic regression which is the prediction \n","def hypothesis(w,insts,m,n):\n","  z = np.dot(insts[:,0:n],w.T)\n","  h = 1/(1+np.exp(-z.astype(np.float32))) #working\n","  return h\n","\n","# cost function for logistic regression\n","def cost(h,insts,lamb,m,w):\n","  c = 0\n","  for i in range(m):\n","    c_te = (-insts_tr[i,-1]*np.log(h[i]) - (1- insts_tr[i,-1])*np.log(1 - h[i]))/m\n","    if not(np.isnan(c_te)) and not(math.isinf(c_te)):\n","      c = c+ c_te\n","  return c + 0.5*lamb*(np.dot(w,w))\n","# update of weight values for logistic regression\n","def update(w,alpha,lamb,insts,h,m,n):\n","  d = np.zeros(n)\n","  for i in range(n):\n","    d[i] = np.dot( (h[0:m]- insts[0:m,-1]),insts[0:m,i] )\n","  for i in range(n):\n","    w[i] = w[i]*(1-alpha*lamb) - alpha*d[i]\n","\n","  return w\n","def update_stotastic(w,alpha,lamb,insts,h,index,n):\n","  d = np.zeros(n)\n","  for i in range(n):\n","    d[i] = (h[index]- insts[index,-1])*insts[index,i] \n","  for i in range(n):\n","    w[i] = w[i]*(1-alpha*lamb) - alpha*d[i]\n","\n","  return w\n","\n","def performance(mat,m):\n","  ind_acc = np.ones(3)\n","  for i in range(3):\n","    ind_acc[i] = mat[i,i]/(mat[i,0]+mat[i,1]+mat[i,2])\n","    print('accuracy for group',end='')\n","    print(i+1, end=': ')\n","    print(ind_acc[i])\n","  print('overall accuracy:',end= ' ')\n","  print((mat[0,0]+mat[1,1]+mat[2,2])/m)\n","\n","  "],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"id":"HvBW74hlKEnf","executionInfo":{"status":"ok","timestamp":1634024265108,"user_tz":-330,"elapsed":11,"user":{"displayName":"HARSHITH GANDHE","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhqqtCT1oqiyI5Eh9zv6fQFnG0ICZb1-YGmzniD-g=s64","userId":"10725924555064938006"}}},"source":["opt_weights = [] # stores the weight values for all the models\n","opt_cost = [] # stores the final optimal cost value at the end of each group"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"id":"lhOSnUfSLBR7","executionInfo":{"status":"ok","timestamp":1634024386451,"user_tz":-330,"elapsed":121353,"user":{"displayName":"HARSHITH GANDHE","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhqqtCT1oqiyI5Eh9zv6fQFnG0ICZb1-YGmzniD-g=s64","userId":"10725924555064938006"}},"outputId":"33ec473b-c82a-4404-e42c-063abd53a2b9"},"source":["for i in range(1,4,1):\n","  train = insts_tr.copy()\n","  val = insts_val.copy()\n","  train[:,-1] = (train[:,-1]==i).astype(int) # assignes the value 1 if the level is i\n","  val[:,-1] = (val[:,-1]==i).astype(int)# assignes the value 0 if the level is not i\n","  m_tr = len(train[:,0])\n","  m_val = len(val[:,0])\n","  itr = 600\n","  alpha = np.linspace(0.001,0.01,100)\n","  lamb = np.linspace(0,100,10)\n","  b_min = 10000\n","  c = np.ones(len(lamb))\n","  w_opt = np.zeros(n)  #stores the optimal weight value\n","  min=0\n","  for j in range(len(lamb)):\n","    for a in alpha:\n","      w = np.random.rand(n)\n","      j_list = np.ones(itr)\n","      for k in range(itr):\n","        h = hypothesis(w,train,m_tr,n)\n","        w = update(w,a,lamb[j],train,h,m_tr,n)\n","      h = hypothesis(w,val,m_val,n)\n","      c[j] = cost(h,val,lamb[j],m_val,w)\n","      if c[j] < b_min:\n","        min = j\n","        b_min = c[j]\n","        w_opt = w  \n","  h = hypothesis(w_opt,train,m_tr,n)\n","  opt_cost.append(cost(h,train,lamb[min],m_tr,w_opt)) # cal the final cost value\n","  opt_weights.append(w_opt) # append the optimal weight values for every group\n","\n","m_te = len(insts_te[:,0])\n","y_acu = insts_te[:,-1].astype(int)\n","y_pre = np.zeros(len(insts_te)).astype(int)\n","y_cost = np.zeros(len(insts_te))\n","i = 1\n","for w in opt_weights:\n","  h_te = hypothesis(w,insts_te,m_te,n)\n","  y_pe = np.round(h_te)\n","  for j in range(len(y_pe)):\n","    if y_pe[j]==1 and y_cost[j]==0:\n","      y_pre[j] = i\n","      y_cost[j] = opt_cost[i-1]\n","    if y_pe[j] == 1 and y_cost[j] !=0:\n","      if y_cost[j]>opt_cost[i-1]:\n","        y_pre[j] = i\n","        y_cost[j] = opt_cost[i-1]\n","  i+=1\n","confusion_matrix = np.zeros(9).reshape(3,3)\n","\n","for i in range(m_te):\n","  if y_pre[i] == y_acu[i]:\n","    idx = y_acu[i]\n","    confusion_matrix[idx-1,idx-1] +=1\n","  else:\n","    confusion_matrix[y_acu[i]-1,y_pre[i]-1] +=1\n","performance(confusion_matrix,m_te)"],"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["accuracy for group1: 0.625\n","accuracy for group2: 0.9375\n","accuracy for group3: 0.8888888888888888\n","overall accuracy: 0.8571428571428571\n"]}]},{"cell_type":"markdown","metadata":{"id":"5pl0_uDfBqpZ"},"source":["# Multiclass Logistic regression + MBG + L2-NORM"]},{"cell_type":"code","metadata":{"id":"UQPnX23RBxxe","executionInfo":{"status":"ok","timestamp":1634024386452,"user_tz":-330,"elapsed":10,"user":{"displayName":"HARSHITH GANDHE","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhqqtCT1oqiyI5Eh9zv6fQFnG0ICZb1-YGmzniD-g=s64","userId":"10725924555064938006"}}},"source":["np.random.shuffle(insts_mb)\n","insts_tr = insts_mb[0:int(m*0.7),:]\n","insts_te = insts_mb[int(m*0.7):int(m*0.9),:]\n","insts_val = insts_mb[int(m*0.9):m,:]"],"execution_count":23,"outputs":[]},{"cell_type":"code","metadata":{"id":"1_YzbZ2VOaF1","executionInfo":{"status":"ok","timestamp":1634024386452,"user_tz":-330,"elapsed":9,"user":{"displayName":"HARSHITH GANDHE","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhqqtCT1oqiyI5Eh9zv6fQFnG0ICZb1-YGmzniD-g=s64","userId":"10725924555064938006"}}},"source":["opt_weights = [] # stores the weight values for all the models\n","opt_cost = [] # stores the final optimal cost value at the end of each group"],"execution_count":24,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"id":"LLtNpxsVOZ3q","executionInfo":{"status":"ok","timestamp":1634024394996,"user_tz":-330,"elapsed":8553,"user":{"displayName":"HARSHITH GANDHE","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhqqtCT1oqiyI5Eh9zv6fQFnG0ICZb1-YGmzniD-g=s64","userId":"10725924555064938006"}},"outputId":"423f327f-31ac-442d-addf-6122038b16ad"},"source":["for i in range(1,4):\n","  train = insts_tr.copy()\n","  val = insts_val.copy()\n","  train[:,-1] = (train[:,-1]==i).astype(int) # assignes the value 1 if the level is i\n","  val[:,-1] = (val[:,-1]==i).astype(int)# assignes the value 0 if the level is not i\n","  m_tr = len(train[:,0])\n","  m_val = len(val[:,0])\n","  itr = 1000\n","  alpha = np.linspace(0.001,0.01,10)\n","  lamb = 10\n","  b_min = 10000\n","  c = np.ones(len(alpha))\n","  w_opt = np.zeros(n)  #stores the optimal weight value\n","  min=0\n","  m_batch = 20\n","\n","  for j in range(len(alpha)):\n","    w = np.random.rand(n)\n","    j_list = np.ones(itr)\n","    for k in range(itr):\n","      np.random.shuffle(train)\n","      h = hypothesis(w,train,m_tr,n)\n","      w = update(w,alpha[j],lamb,train,h,m_batch,n)\n","    h = hypothesis(w,val,m_val,n)\n","    c[j] = cost(h,val,lamb,m_val,w)\n","    if c[j] < b_min:\n","      min = j\n","      b_min = c[j]\n","      w_opt = w  \n","  h = hypothesis(w_opt,train,m_tr,n)\n","  opt_cost.append(cost(h,train,lamb,m_tr,w_opt)) # cal the final cost value\n","  opt_weights.append(w_opt) # append the optimal weight values for every group\n","\n","m_te = len(insts_te[:,0])\n","y_acu = insts_te[:,-1].astype(int)\n","y_pre = np.zeros(len(insts_te)).astype(int)\n","y_cost = np.zeros(len(insts_te))\n","i = 1\n","for w in opt_weights:\n","  h_te = hypothesis(w,insts_te,m_te,n)\n","  y_pe = np.round(h_te)\n","  for j in range(len(y_pe)):\n","    if y_pe[j]==1 and y_cost[j]==0:\n","      y_pre[j] = i\n","      y_cost[j] = opt_cost[i-1]\n","    if y_pe[j] == 1 and y_cost[j] !=0:\n","      if y_cost[j]>opt_cost[i-1]:\n","        y_pre[j] = i\n","        y_cost[j] = opt_cost[i-1]\n","  i+=1\n","confusion_matrix = np.zeros(9).reshape(3,3)\n","\n","for i in range(m_te):\n","  if y_pre[i] == y_acu[i]:\n","    idx = y_acu[i]\n","    confusion_matrix[idx-1,idx-1] +=1\n","  else:\n","    confusion_matrix[y_acu[i]-1,y_pre[i]-1] +=1\n","performance(confusion_matrix,m_te)"],"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["accuracy for group1: 0.8823529411764706\n","accuracy for group2: 1.0\n","accuracy for group3: 0.8235294117647058\n","overall accuracy: 0.8809523809523809\n"]}]},{"cell_type":"markdown","metadata":{"id":"9ATm1WS_ByZ6"},"source":["# Multiclass Logistic regression + SGD + L2-NORM"]},{"cell_type":"code","metadata":{"id":"9aalPVWYuBhr","colab":{"base_uri":"https://localhost:8080/","height":0},"executionInfo":{"status":"ok","timestamp":1634024535115,"user_tz":-330,"elapsed":12119,"user":{"displayName":"HARSHITH GANDHE","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhqqtCT1oqiyI5Eh9zv6fQFnG0ICZb1-YGmzniD-g=s64","userId":"10725924555064938006"}},"outputId":"46a3aa68-f84d-4762-c47b-6af049195b96"},"source":["%reset-f\n","import pandas as pd\n","import numpy as np\n","from matplotlib import pyplot as plt \n","import math\n","import copy\n","path = '/content/drive/MyDrive/ML/data_q6_q7.xlsx' \n","df = pd.read_excel(path)\n","insts = df.to_numpy()\n","m= len(insts[:,0]) #No of instinces\n","ones = np.ones((m,1))\n","insts = np.append(ones,insts,axis=1)\n","n = len(insts[0,:])-1 #no of features including f0 n=31\n","for i in range(1,n,1):\n","  insts[:,i] = (insts[:,i] - insts[:,i].mean())/insts[:,i].std() #Normalize the data\n","np.random.shuffle(insts)\n","insts_tr = insts[0:int(m*0.7),:]\n","insts_te = insts[int(m*0.7):int(m*0.9),:]\n","insts_val = insts[int(m*0.9):m,:]\n","# hypothesis for logistic regression which is the prediction \n","def hypothesis(w,insts,m,n):\n","  z = np.dot(insts[:,0:n],w.T)\n","  h = 1/(1+np.exp(-z.astype(np.float32))) #working\n","  return h\n","\n","# cost function for logistic regression\n","def cost(h,insts,lamb,m,w):\n","  c = 0\n","  for i in range(m):\n","    c_te = (-insts_tr[i,-1]*np.log(h[i]) - (1- insts_tr[i,-1])*np.log(1 - h[i]))/m\n","    if not(np.isnan(c_te)) and not(math.isinf(c_te)):\n","      c = c+ c_te\n","  return c + 0.5*lamb*(np.dot(w,w))\n","# update of weight values for logistic regression\n","def update(w,alpha,lamb,insts,h,m,n):\n","  d = np.zeros(n)\n","  for i in range(n):\n","    d[i] = np.dot( (h[0:m]- insts[0:m,-1]),insts[0:m,i] )\n","  for i in range(n):\n","    w[i] = w[i]*(1-alpha*lamb) - alpha*d[i]\n","\n","  return w\n","def update_stotastic(w,alpha,lamb,insts,h,index,n):\n","  d = np.zeros(n)\n","  for i in range(n):\n","    d[i] = (h[index]- insts[index,-1])*insts[index,i] \n","  for i in range(n):\n","    w[i] = w[i]*(1-alpha*lamb) - alpha*d[i]\n","\n","  return w\n","\n","def performance(mat,m):\n","  ind_acc = np.ones(3)\n","  for i in range(3):\n","    ind_acc[i] = mat[i,i]/(mat[i,0]+mat[i,1]+mat[i,2])\n","    print('accuracy for group',end='')\n","    print(i+1, end=': ')\n","    print(ind_acc[i])\n","  print('overall accuracy:',end= ' ')\n","  print((mat[0,0]+mat[1,1]+mat[2,2])/m)\n","\n","  \n","opt_weights_s = [] # stores the weight values for all the models\n","opt_cost_s = [] # stores the final optimal cost value at the end of each group\n","for i in range(1,4):\n","  train = copy.deepcopy(insts_tr)\n","  val = copy.deepcopy(insts_val)\n","  train[:,-1] = (train[:,-1]==i).astype(int) # assignes the value 1 if the level is i\n","  val[:,-1] = (val[:,-1]==i).astype(int)# assignes the value 0 if the level is not i\n","  m_tr = len(train[:,0])\n","  m_val = len(val[:,0])\n","  itr = np.linspace(100,1000,10).astype(int)\n","  alpha = np.linspace(0.0001,0.001,10)\n","  lamb = 10\n","  b_min = 10000\n","  c = np.ones(len(alpha))\n","  w_opt = np.zeros(n)  #stores the optimal weight value\n","  min=0\n","  \n","\n","  for j in range(len(alpha)):\n","    for it in itr:\n","      w = np.random.rand(n)\n","      \n","      for k in range(it):\n","        index = np.random.randint(m_tr)\n","        h = hypothesis(w,train,m_tr,n)\n","        w = update_stotastic(w,alpha[j],lamb,train,h,index,n)\n","      h = hypothesis(w,val,m_val,n)\n","      c[j] = cost(h,val,lamb,m_val,w)\n","      if c[j] < b_min:\n","        min = j\n","        b_min = c[j]\n","        w_opt = w  \n","  h = hypothesis(w_opt,train,m_tr,n)\n","  opt_cost_s.append(cost(h,train,lamb,m_tr,w_opt)) # cal the final cost value\n","  opt_weights_s.append(w_opt) # append the optimal weight values for every group\n","\n","m_te = len(insts_te[:,0])\n","y_acu = insts_te[:,-1].astype(int)\n","y_pre = np.zeros(len(insts_te)).astype(int)\n","y_cost = np.zeros(len(insts_te))\n","i = 1\n","for w in opt_weights_s:\n","  h_te = hypothesis(w,insts_te,m_te,n)\n","  y_pe = np.round(h_te)\n","  for j in range(len(y_pe)):\n","    if y_pe[j]==1 and y_cost[j]==0:\n","      y_pre[j] = i\n","      y_cost[j] = opt_cost_s[i-1]\n","    if y_pe[j] == 1 and y_cost[j] !=0:\n","      if y_cost[j]>opt_cost_s[i-1]:\n","        y_pre[j] = i\n","        y_cost[j] = opt_cost_s[i-1]\n","  i+=1\n","y_actual = pd.Series(y_acu, name='Actual')\n","y_pred = pd.Series(y_pre, name='Predicted')\n","confmat = pd.crosstab(y_actual, y_pred)\n","confmat = np.asarray(confmat)\n","\n","performance(confmat,m_te)"],"execution_count":32,"outputs":[{"output_type":"stream","name":"stdout","text":["accuracy for group1: 0.36363636363636365\n","accuracy for group2: 0.08333333333333333\n","accuracy for group3: 0.8947368421052632\n","overall accuracy: 0.5238095238095238\n"]}]},{"cell_type":"markdown","metadata":{"id":"apVAWSFrB8fK"},"source":["# Multiclass Logistic regression + BGD + L1-NORM"]},{"cell_type":"code","metadata":{"id":"IKtAq3tZCABF","executionInfo":{"status":"ok","timestamp":1634024553837,"user_tz":-330,"elapsed":619,"user":{"displayName":"HARSHITH GANDHE","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhqqtCT1oqiyI5Eh9zv6fQFnG0ICZb1-YGmzniD-g=s64","userId":"10725924555064938006"}}},"source":["%reset-f"],"execution_count":33,"outputs":[]},{"cell_type":"code","metadata":{"id":"9eAd6ZmQQAH0","executionInfo":{"status":"ok","timestamp":1634024585126,"user_tz":-330,"elapsed":369,"user":{"displayName":"HARSHITH GANDHE","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhqqtCT1oqiyI5Eh9zv6fQFnG0ICZb1-YGmzniD-g=s64","userId":"10725924555064938006"}}},"source":["import pandas as pd\n","import numpy as np\n","from matplotlib import pyplot as plt \n","import math\n","import copy"],"execution_count":34,"outputs":[]},{"cell_type":"code","metadata":{"id":"LhheRU0fP__x","executionInfo":{"status":"ok","timestamp":1634024592008,"user_tz":-330,"elapsed":402,"user":{"displayName":"HARSHITH GANDHE","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhqqtCT1oqiyI5Eh9zv6fQFnG0ICZb1-YGmzniD-g=s64","userId":"10725924555064938006"}}},"source":["path = '/content/drive/MyDrive/ML/data_q6_q7.xlsx' \n","df = pd.read_excel(path)\n","insts = df.to_numpy()\n","m= len(insts[:,0]) #No of instinces\n","ones = np.ones((m,1))\n","insts = np.append(ones,insts,axis=1)\n","n = len(insts[0,:])-1 #no of features including f0 n=31\n","for i in range(1,n,1):\n","  insts[:,i] = (insts[:,i] - insts[:,i].mean())/insts[:,i].std() #Normalize the data\n","insts_mb = copy.deepcopy(insts)\n","insts_s = copy.deepcopy(insts)\n","np.random.shuffle(insts)\n","insts_tr = insts[0:int(m*0.7),:]\n","insts_te = insts[int(m*0.7):int(m*0.9),:]\n","insts_val = insts[int(m*0.9):m,:]"],"execution_count":35,"outputs":[]},{"cell_type":"code","metadata":{"id":"-sQUaiNRP_4R","executionInfo":{"status":"ok","timestamp":1634024597061,"user_tz":-330,"elapsed":608,"user":{"displayName":"HARSHITH GANDHE","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhqqtCT1oqiyI5Eh9zv6fQFnG0ICZb1-YGmzniD-g=s64","userId":"10725924555064938006"}}},"source":["# hypothesis for logistic regression which is the prediction \n","def hypothesis(w,insts,m,n):\n","  z = np.dot(insts[:,0:n],w.T)\n","  h = 1/(1+np.exp(-z.astype(np.float32))) #working\n","  return h\n","\n","# cost function for logistic regression\n","def cost(h,insts,lamb,m,w):\n","  c = 0\n","  for i in range(m):\n","    c_te = (-insts_tr[i,-1]*np.log(h[i]) - (1- insts_tr[i,-1])*np.log(1 - h[i]))/m\n","    if not(np.isnan(c_te)) and not(math.isinf(c_te)):\n","      c = c+ c_te\n","  w_abs = np.absolute(w)\n","  w_abs = np.sum(w_abs)\n","  return c/m + 0.5*lamb*(w_abs)\n","# update of weight values for logistic regression\n","def update(w,alpha,lamb,insts,h,m,n):\n","  d = np.zeros(n)\n","  for i in range(n):\n","    d[i] = np.dot( (h[0:m]- insts[0:m,-1]),insts[0:m,i] )\n","  for i in range(n):\n","    w[i] = (w[i]-alpha*lamb*np.sign(w[i])) - alpha*d[i]\n","\n","  return w\n","def update_stotastic(w,alpha,lamb,insts,h,index,n):\n","  d = np.zeros(n)\n","  for i in range(n):\n","    d[i] = (h[index]- insts[index,-1])*insts[index,i] \n","  for i in range(n):\n","    w[i] = (w[i]-alpha*lamb*np.sign(w[i])) - alpha*d[i]\n","\n","  return w\n","\n","def performance(mat,m):\n","  for i in range(3):\n","    ia = mat[i,i]/(mat[i,0]+mat[i,1]+mat[i,2])\n","    print('accuracy for group',end='')\n","    print(i+1, end=': ')\n","    print(ia)\n","  print('overall accuracy:',end= ' ')\n","  print((mat[0,0]+mat[1,1]+mat[2,2])/m)"],"execution_count":36,"outputs":[]},{"cell_type":"code","metadata":{"id":"xdvGM9hqQkaa","executionInfo":{"status":"ok","timestamp":1634024600774,"user_tz":-330,"elapsed":421,"user":{"displayName":"HARSHITH GANDHE","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhqqtCT1oqiyI5Eh9zv6fQFnG0ICZb1-YGmzniD-g=s64","userId":"10725924555064938006"}}},"source":["opt_weights = [] # stores the weight values for all the models\n","opt_cost = [] # stores the final optimal cost value at the end of each group"],"execution_count":37,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"id":"DI2SUbXjcSm4","executionInfo":{"status":"ok","timestamp":1634024629933,"user_tz":-330,"elapsed":26643,"user":{"displayName":"HARSHITH GANDHE","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhqqtCT1oqiyI5Eh9zv6fQFnG0ICZb1-YGmzniD-g=s64","userId":"10725924555064938006"}},"outputId":"4c774377-430c-4338-c7cf-2309f4fc34c0"},"source":["for i in range(1,4):\n","  train = insts_tr.copy()\n","  val = insts_val.copy()\n","  train[:,-1] = (train[:,-1]==i).astype(int) # assignes the value 1 if the level is i\n","  val[:,-1] = (val[:,-1]==i).astype(int)# assignes the value 0 if the level is not i\n","  m_tr = len(train[:,0])\n","  m_val = len(val[:,0])\n","  itr = 1000\n","  alpha = np.linspace(0.001,0.01,10)\n","  lamb = np.linspace(0,100,10)\n","  b_min = 10000\n","  c = np.ones(len(lamb))\n","  w_opt = np.zeros(n)  #stores the optimal weight value\n","  min=0\n","  for j in range(len(lamb)):\n","    for a in alpha:\n","      w = np.random.rand(n)\n","      j_list = np.ones(itr)\n","      for k in range(itr):\n","        h = hypothesis(w,train,m_tr,n)\n","        w = update(w,a,lamb[j],train,h,m_tr,n)\n","      h = hypothesis(w,val,m_val,n)\n","      c[j] = cost(h,val,lamb[j],m_val,w)\n","      if c[j] < b_min:\n","        min = j\n","        b_min = c[j]\n","        w_opt = w  \n","  h = hypothesis(w_opt,train,m_tr,n)\n","  opt_cost.append(cost(h,train,lamb[min],m_tr,w_opt)) # cal the final cost value\n","  opt_weights.append(w_opt) # append the optimal weight values for every group\n","\n","m_te = len(insts_te[:,0])\n","y_acu = insts_te[:,-1].astype(int)\n","y_pre = np.zeros(len(insts_te)).astype(int)\n","y_cost = np.zeros(len(insts_te))\n","i = 1\n","for w in opt_weights:\n","  h_te = hypothesis(w,insts_te,m_te,n)\n","  y_pe = np.round(h_te)\n","  for j in range(len(y_pe)):\n","    if y_pe[j]==1 and y_cost[j]==0:\n","      y_pre[j] = i\n","      y_cost[j] = opt_cost[i-1]\n","    if y_pe[j] == 1 and y_cost[j] !=0:\n","      if y_cost[j]>opt_cost[i-1]:\n","        y_pre[j] = i\n","        y_cost[j] = opt_cost[i-1]\n","  i+=1\n","confusion_matrix = np.zeros(9).reshape(3,3)\n","\n","for i in range(m_te):\n","  if y_pre[i] == y_acu[i]:\n","    idx = y_acu[i]\n","    confusion_matrix[idx-1,idx-1] +=1\n","  else:\n","    confusion_matrix[y_acu[i]-1,y_pre[i]-1] +=1\n","performance(confusion_matrix,m_te)"],"execution_count":38,"outputs":[{"output_type":"stream","name":"stdout","text":["accuracy for group1: 0.8666666666666667\n","accuracy for group2: 1.0\n","accuracy for group3: 0.9230769230769231\n","overall accuracy: 0.9285714285714286\n"]}]},{"cell_type":"markdown","metadata":{"id":"CkdxAMKzCAqA"},"source":["# Multiclass Logistic regression + MBG + L1-NORM"]},{"cell_type":"code","metadata":{"id":"67EXac-_CFHN","executionInfo":{"status":"ok","timestamp":1634024705903,"user_tz":-330,"elapsed":541,"user":{"displayName":"HARSHITH GANDHE","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhqqtCT1oqiyI5Eh9zv6fQFnG0ICZb1-YGmzniD-g=s64","userId":"10725924555064938006"}}},"source":["np.random.shuffle(insts_mb)\n","insts_tr = insts_mb[0:int(m*0.7),:]\n","insts_te = insts_mb[int(m*0.7):int(m*0.9),:]\n","insts_val = insts_mb[int(m*0.9):m,:]"],"execution_count":48,"outputs":[]},{"cell_type":"code","metadata":{"id":"cX57YJb2dVJZ","executionInfo":{"status":"ok","timestamp":1634024707578,"user_tz":-330,"elapsed":2,"user":{"displayName":"HARSHITH GANDHE","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhqqtCT1oqiyI5Eh9zv6fQFnG0ICZb1-YGmzniD-g=s64","userId":"10725924555064938006"}}},"source":["opt_weights = [] # stores the weight values for all the models\n","opt_cost = [] # stores the final optimal cost value at the end of each group"],"execution_count":49,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"id":"YL273WRndXtK","executionInfo":{"status":"ok","timestamp":1634024717912,"user_tz":-330,"elapsed":8621,"user":{"displayName":"HARSHITH GANDHE","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhqqtCT1oqiyI5Eh9zv6fQFnG0ICZb1-YGmzniD-g=s64","userId":"10725924555064938006"}},"outputId":"91f98cfb-06f3-4e22-d04d-f36404307265"},"source":["for i in range(1,4):\n","  train = insts_tr.copy()\n","  val = insts_val.copy()\n","  train[:,-1] = (train[:,-1]==i).astype(int) # assignes the value 1 if the level is i\n","  val[:,-1] = (val[:,-1]==i).astype(int)# assignes the value 0 if the level is not i\n","  m_tr = len(train[:,0])\n","  m_val = len(val[:,0])\n","  itr = 1000\n","  alpha = np.linspace(0.001,0.01,10)\n","  lamb = 10\n","  b_min = 10000\n","  c = np.ones(len(alpha))\n","  w_opt = np.zeros(n)  #stores the optimal weight value\n","  min=0\n","  m_batch = 20\n","\n","  for j in range(len(alpha)):\n","    w = np.random.rand(n)\n","    j_list = np.ones(itr)\n","    for k in range(itr):\n","      np.random.shuffle(train)\n","      h = hypothesis(w,train,m_tr,n)\n","      w = update(w,alpha[j],lamb,train,h,m_batch,n)\n","    h = hypothesis(w,val,m_val,n)\n","    c[j] = cost(h,val,lamb,m_val,w)\n","    if c[j] < b_min:\n","      min = j\n","      b_min = c[j]\n","      w_opt = w  \n","  h = hypothesis(w_opt,train,m_tr,n)\n","  opt_cost.append(cost(h,train,lamb,m_tr,w_opt)) # cal the final cost value\n","  opt_weights.append(w_opt) # append the optimal weight values for every group\n","\n","m_te = len(insts_te[:,0])\n","y_acu = insts_te[:,-1].astype(int)\n","y_pre = np.zeros(len(insts_te)).astype(int)\n","y_cost = np.zeros(len(insts_te))\n","i = 1\n","for w in opt_weights:\n","  h_te = hypothesis(w,insts_te,m_te,n)\n","  y_pe = np.round(h_te)\n","  for j in range(len(y_pe)):\n","    if y_pe[j]==1 and y_cost[j]==0:\n","      y_pre[j] = i\n","      y_cost[j] = opt_cost[i-1]\n","    if y_pe[j] == 1 and y_cost[j] !=0:\n","      if y_cost[j]>opt_cost[i-1]:\n","        y_pre[j] = i\n","        y_cost[j] = opt_cost[i-1]\n","  i+=1\n","confusion_matrix = np.zeros(9).reshape(3,3)\n","\n","for i in range(m_te):\n","  if y_pre[i] == y_acu[i]:\n","    idx = y_acu[i]\n","    confusion_matrix[idx-1,idx-1] +=1\n","  else:\n","    confusion_matrix[y_acu[i]-1,y_pre[i]-1] +=1\n","performance(confusion_matrix,m_te)"],"execution_count":50,"outputs":[{"output_type":"stream","name":"stdout","text":["accuracy for group1: 0.0\n","accuracy for group2: 1.0\n","accuracy for group3: 1.0\n","overall accuracy: 0.6666666666666666\n"]}]},{"cell_type":"markdown","metadata":{"id":"RzuTlXVxCFp0"},"source":["# Multiclass Logistic regression + SGD + L1-NORM"]},{"cell_type":"code","metadata":{"id":"VDLNFEiwCIue","executionInfo":{"status":"ok","timestamp":1634024896003,"user_tz":-330,"elapsed":353,"user":{"displayName":"HARSHITH GANDHE","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhqqtCT1oqiyI5Eh9zv6fQFnG0ICZb1-YGmzniD-g=s64","userId":"10725924555064938006"}}},"source":["np.random.shuffle(insts_s)\n","insts_tr = insts_s[0:int(m*0.7),:]\n","insts_te = insts_s[int(m*0.7):int(m*0.9),:]\n","insts_val = insts_s[int(m*0.9):m,:]"],"execution_count":91,"outputs":[]},{"cell_type":"code","metadata":{"id":"6xSdjANXdzNq","executionInfo":{"status":"ok","timestamp":1634024898057,"user_tz":-330,"elapsed":2,"user":{"displayName":"HARSHITH GANDHE","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhqqtCT1oqiyI5Eh9zv6fQFnG0ICZb1-YGmzniD-g=s64","userId":"10725924555064938006"}}},"source":["opt_weights_s = [] # stores the weight values for all the models\n","opt_cost_s = [] # stores the final optimal cost value at the end of each group"],"execution_count":92,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"id":"Yd-gfp36d3Rg","executionInfo":{"status":"ok","timestamp":1634024902081,"user_tz":-330,"elapsed":2442,"user":{"displayName":"HARSHITH GANDHE","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhqqtCT1oqiyI5Eh9zv6fQFnG0ICZb1-YGmzniD-g=s64","userId":"10725924555064938006"}},"outputId":"df34906a-ac41-4c3c-f26f-239ac916bb48"},"source":["for i in range(1,4):\n","  train = insts_tr.copy()\n","  val = insts_val.copy()\n","  train[:,-1] = (train[:,-1]==i).astype(int) # assignes the value 1 if the level is i\n","  val[:,-1] = (val[:,-1]==i).astype(int)# assignes the value 0 if the level is not i\n","  m_tr = len(train[:,0])\n","  m_val = len(val[:,0])\n","  itr = 1000\n","  alpha = np.linspace(0.0001,0.001,10)\n","  lamb = 10\n","  b_min = 10000\n","  c = np.ones(len(alpha))\n","  w_opt = np.zeros(n)  #stores the optimal weight value\n","  min=0\n","  \n","\n","  for j in range(len(alpha)):\n","    w = np.random.rand(n)\n","    j_list = np.ones(itr)\n","    for k in range(itr):\n","      index = np.random.randint(m_tr)\n","      h = hypothesis(w,train,m_tr,n)\n","      w = update_stotastic(w,alpha[j],lamb,train,h,index,n)\n","    h = hypothesis(w,val,m_val,n)\n","    c[j] = cost(h,val,lamb,m_val,w)\n","    if c[j] < b_min:\n","      min = j\n","      b_min = c[j]\n","      w_opt = w  \n","  h = hypothesis(w_opt,train,m_tr,n)\n","  opt_cost_s.append(cost(h,train,lamb,m_tr,w_opt)) # cal the final cost value\n","  opt_weights_s.append(w_opt) # append the optimal weight values for every group\n","\n","m_te = len(insts_te[:,0])\n","y_acu = insts_te[:,-1].astype(int)\n","y_pre = np.zeros(len(insts_te)).astype(int)\n","y_cost = np.zeros(len(insts_te))\n","i = 1\n","for w in opt_weights_s:\n","  h_te = hypothesis(w,insts_te,m_te,n)\n","  y_pe = np.round(h_te)\n","  for j in range(len(y_pe)):\n","    if y_pe[j]==1 and y_cost[j]==0:\n","      y_pre[j] = i\n","      y_cost[j] = opt_cost_s[i-1]\n","    if y_pe[j] == 1 and y_cost[j] !=0:\n","      if y_cost[j]>opt_cost_s[i-1]:\n","        y_pre[j] = i\n","        y_cost[j] = opt_cost_s[i-1]\n","  i+=1\n","confusion_matrix = np.zeros(9).reshape(3,3)\n","\n","for i in range(m_te):\n","  if y_pre[i] == y_acu[i]:\n","    idx = y_acu[i]\n","    confusion_matrix[idx-1,idx-1] +=1\n","  else:\n","    confusion_matrix[y_acu[i]-1,y_pre[i]-1] +=1\n","performance(confusion_matrix,m_te)"],"execution_count":93,"outputs":[{"output_type":"stream","name":"stdout","text":["accuracy for group1: 0.15384615384615385\n","accuracy for group2: 0.9166666666666666\n","accuracy for group3: 0.9411764705882353\n","overall accuracy: 0.6904761904761905\n"]}]}]}